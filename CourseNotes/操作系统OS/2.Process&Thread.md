### Warm up

- 以下都是特指 Linux
- 2 stage booting in Linux
	- 先引导 Grub 再引导 OS
- the first process
	- init 进程：所有进程的父进程
		- 先检查 /etc/initab 文件来决定运行等级
		- 然后运行后台进程（守护进程 daemon）
- process hierarchies
	- ps -al
	- pstree

# Processes
## Definition
- Process Control Block
	- Addr space
	- Global variable
	- Open files
	- Child processes
	- Pending alarms
	- Signals and their handlers
	- Accounting info

## fork() and exec()
- 如何实现 fork
	- 新建一个 PCB
	- 创建新的地址空间
	- 把父进程地址空间的内容拷过去
	- 继承父进程的上下文
	- ？
	- 把程序加载到当前地址空间
	- 复制参数
	- 在 start 开始运行
- Why fork and execve?
	- 可以继承父进程的一些信息（fd、groupID、dir、调度信息 等）
	- 可以先修改上下文然后 execve
	- e.g. 终端的设计
		- fork 一个，原来的 execve 掉
		- 子进程继承了父进程的 fd
		- 重定向：改一下 fd 再 execve
		- 管道：pipe object 提供了两个文件描述符，一个只读端，一个只写端
			- fork 之前，先创建一个 pipe 对象
			- 有一段空间，先开个只写端给第一个写，然后关掉只写端开只读段给下一个读
	- Windows `CreateProcess` API
		- fork + execve
		- stupid (x
- 然而事实上现在底层的 fork 已经被扬了，fork 变成了 clone 的 wrapper 函数
	- 现在是搞个进程专门用来 clone
	- 效果是一样的
- exit()
	- 该函数不会返回
	- 关掉文件，释放内存。。。（？
	- 把父进程 pid 设为 1（init 进程）
	- 给原来的父进程发送 SIGCHILD 信号（你孩子寄了

## Process State
- new
- ready
- running
- waiting
- terminated
- ![操作系统OS/attachments/Pasted image 20220309080639.png](attachments/Pasted%20image%2020220309080639.png)
- Orphan 孤儿进程
- 父进程先寄了
- 解决办法：让 init 变成他的父进程（把父进程 pid 设为 1
- Zombie 僵尸进程
- 父进程还没 wait 就先寄了
- 内核会让他变成僵尸态
- kill init 进程？
	- 发送 SIGKILL (kill -9 pid) 则除了 init 进程都不能忽略它，也不能完成清理等工作，就直接寄了
	- SIGINT (Ctrl-C) 进程是可以完成清理工作的
	- signal 库函数：自定义处理函数
	- ![[操作系统OS/attachments/Pasted image 20220309081711.png]]

## Multitasking
- 进程可能会有中断、异步通信等
- Our Goal：使 CPU 一直有活干
- 一个朴素的模型：
	- 一个程序等 IO 的概率为 p
	- 则 CPU 利用率 $= 1 - p^n$，n为进程数
	- 然而并不是独立事件
- 如何选择进程？

## Scheduling
- ready queues and waiting queues
	- 可以用链表实现
- 上下文切换
	- Context is stored in PCB
	- Context switch 所用时间就相当于浪费了
	- 有些 nb 的 CPU 有好多套寄存器，可以一起加载好多 Context
- Preempting 抢占
	- 计时器终端 Timer Interrrupt

## 进程交互 IPC
- 三种交互模式
	- Producer-Consumer
		- 单向交互
	- Server-Client
		- 双向交互
	- Filesystem
- 一些经典实现方法（下面三级标题全是
	- Shared memory
	- Message passing
	- ![[操作系统OS/attachments/Pasted image 20220309092353.png]]

### Shared Memory
#### Producer-Consumer 的 Shared Memory 实现
- 有两种方式
	- unbounded-buffer
		- 生产者不需要等待消费者读
	- bounded-buffer
		- 当 buffer 满了生产者可能要等
- bounded-buffer 的循环队列实现
	- ppt 80 页起[ppt](操作系统OS/attachments/Chapter02-Processes and Threads.pdf)
	- 为什么要空一格？
		- 否则 in out 指针重合既可以表示队列全空也可以表示全满
	- improve：使用 in 指针和 counter 变量用来维护当前存过多少变量
		- 出现愚蠢的事情：counter++ 操作涉及三次操作
		- 在这三次操作之间被 Timer Interrupt 了就寄了
		- 生产者还没写回就被消费者-1了
		- in out 实现就没有这个问题，因为两者修改的不是同一个变量

### Message Passing
- 信息传输：同步、异步
	- 阻塞就是同步，发送者和接收者在有效传输之前都会被阻塞住
	- 不阻塞就是异步，发了就不管了，接收方能收到有效信息或者空信息
- 异步通信则需要 buffer

- 问题：通信时的异常
	- 消息还没送到，发送方寄了
	- 或者接收方寄了
- 解决：ack & timeout
	- 接收方发送 ack 表示收到了（acknowledge
	- 一段时间没收到 ack 就重发
	- 重发几次后就 timeout
	- 实际上还有别的问题，得学计网（

- 问题：Message Corruption
- 解决：校验码

#### 两种方法比较
- Memory Sharing 一旦建立起来更快，但是可能会有竞争、cache 不同步等问题
- Message Passing 更容易实现，更适用于分布式系统
> ### IPC Examples - POSIX
> - 不抄了 看ppt

### 套接字 Sockets
- TCP UDP
> Example in Java
> - 看 ppt

### Pipes
- treated like a file

### Named Pipes
- 有文件名，别的程序也可以访问
- 使用管道的进程没有父子关系

### Signals

### 信号量 Semaphor、屏障 Barrier 等
- 见 [IPC](4.Sync&Deadlock.md)
# Threads
- 传统 fork 的问题：太笨重，并不需要全部抄下来
	- 只需要共享这些内存资源即可

## Definition
- A single unique execution context
- 单独的 Context
- a semi-process, lightweight process
	- 这就是 linux 的 fork 后来不是真正 fork 的原因
- **线程只代表一个执行的环境，代码数据都是共享的，因此 TCB 只有栈指针、寄存器和一些元数据**

## Motivation
- a unit of concurrency
- a semi-process
- applicable senario: have the same addr space, share all the data

## Thread Model
- TCB: Thread Control Block
	- PC
	- Registers
	- Stack
	- State
- 线程之间没有保护机制

## Operation
- thread_create(thread, func, arg)
	- 创建线程，执行 func 函数，参数为 arg
- thread_join(thread)
	- 等待子线程，获得其返回值
- thread_yield()
	- 线程自己放弃 CPU
- thread_exit(ret)
	- 结束当前线程，清理垃圾，返回给 join 它的人
- 实际上 POSIX 真正能用的接口前面要加个 p
	- 例如 pthread_create 就可以 man 了
	- POSIX 还有两个
- 线程只要不主动退出，可以一直运行

## Thread States
- ![操作系统OS/attachments/Pasted image 20220311114525.png](attachments/Pasted%20image%2020220311114525.png)

## Implementation
### User-Level
- 所有调度都在用户态由用户程序完成
- 内核不知道线程，只知道用户的进程
- 优点：快
- 缺点：没有内核的高级调度功能，一个线程卡住就全卡住了

### Kernel-Level
- 优点：OS 可以进行 nb 的优化、调度，不会被卡住
- 缺点：切换 Context 全都要陷入内核，使用额外时间，增加 OS 复杂性

### Hybrid Implementation
- 用户线程被映射到内核线程，可以一一映射也可以一个内核线程对应多个用户线程

### 内核线程的 Context Switch
- 和 Process 差不多，看 ppt

### 用户线程的 Context Switch
- 没有 OS 的支持
- 可以注册一个信号处理函数
	- 要调度的时候用注册的信号陷入 OS
	- OS 帮你转到信号处理函数

# 调度 Sheduling
## Basics
- when to shedule
	- new process
	- process exit
	- blocked
	- I/O interrupt
	- HW clock interrupt
		- 最后三个：是否需要考虑换一个进程执行
- preemptive 抢占式：到一定的时间中断就重新选择进程
	- nonpreemptive：一直跑直到退出或者阻塞或者自陷
- 流程：
	- 保存上下文
	- 选一个进程
	- 恢复上下文
- 种类：
	- 批处理系统
	- 交互式系统
	- 实时系统（要求在某个时间内返回结果
- Goals
	- Fairness
	- batch 系统的性能度量
		- 吞吐量 thoughout: 单位时间内完成的工作
		- 周转时间 turnaround time: 一个任务从提交到完成的时间
		- CPU 利用率 CPU utilization: 越高越好
		- 能够使吞吐量最大化的调度算法不 一定就有最小的周转时间。
			- 因为吞吐量只看任务数量，不考虑时间
			- 例如,对于确定的短作业和长作业的一个组合,总是运行短作业而不运行长作业的调度程序,可能会获得出色的吞吐性能(每小时大量的短作业) , 但是其代价是对千长的作业周转时间很 差。 如果短作业以一 个稳定的速率不断到达,长作业可能根本运行不了,这样平均周转时间是无限长,但是得到了高的吞吐址。
	- 交互系统关注的
		- 响应时间 less waiting
	- 实时系统关注的
		- deadline

## Batch 系统调度算法
### first come first served (FCFS)
- 缺点
	- 大任务先来会寄
- 优点
	- 最小化 overhead

### shortest job first (SJF)
- Best for turnaround time
- 问题：Starvation：用时多的进程一直跑不了

### shortest remaining time first (SRTF)
- 如果进程并不是同时到达，则 SJF 就需要改变了
- 改良版 preemptive SJF

- 以上三种在不考虑 overhead 的情况下总用时是一样的
- 还有一个问题：我们不知道某一个进程会用多少时间，如何估计？

### 估计运行时间
- 通过当前 CPU slice （？）的使用情况估计将来的时间![[操作系统OS/attachments/Pasted image 20220318112610.png]]
	- （什么是 CPU burst？
- 和上一步有关，和上上步关系较小……
	- 指数级衰减
- ![[操作系统OS/attachments/Pasted image 20220318112712.png]]

## 交互式系统调度算法
### Round Robin (RR) 轮转调度
- means 循环赛制
- 排个队，用完 time slice (time quantum) 就滚去队尾
- 如果没用完就停下来了，也会立即切换到别的进程
- quantum 不能太小：
	- 通常 quantum 10-100ms, context switch <10ms
	- 也不能太大
		- 否则就变成 FCFS 了
- 好处：minimize variance of turnaround time、非常公平
	- 看视频的时候会比较平滑（？
- 坏处：turnaround time、response time 都炸了！
	- overhead 也不小

### Priority Sheduling - 两种方法
- with RR
	- 和 round robin 结合：
		- 在同优先级内 RR
		- 先跑优先级高的
	- 一般数字小代表优先级高
- Multilevel Queue
	- 同优先级内 FCFS
	- 还是有 Starvation 的问题：低优先级一直不会被执行

### Multiple Queues Feedback (MQF)
- 进程可以在不同优先级的队列中移动
- 同优先级使用 RR
- 高优先级队列 time slice 短
	- 低优先级队列 time slice 长
	- 一般成等比增长
- （？？

#### Multilevel Feedback Queue (MFQ)
- 用完 slice 去下一优先级
- 高优先级 slice 小，低优先级 slice 大
- 还是有 starvation 的问题
- starvation 的解决方法 Aging：
	- 一段时间增加所有进程的优先级
	- 最简单的办法是全部提到最高优先级

#### 戏弄 OS
- 过一会发一个 IO 请求就可以呆在高优先级

### Guaranteed Scheduling
- 这种一般不是用来进程间调度的，一般是在多用户的系统上在不同用户间分配 CPU 资源，每个用户都会占用很长时间的 CPU

#### Fair Share
- 是一种 Guaranteed Scheduling
- 向用户保证每个程序平分 CPU 资源
- 跟踪每个用户程序使用 CPU 的比例
	- 运行当前运行时间比例最小的用户程序
- 是 user-level，每个用户能够使用一定比例的 CPU，而不是跟踪每个进程
	- 在多用户系统上比较常用

#### Lottery Sheduling

## Fairness
### Max-min Fairness（？
- Maximal  the minimal allocation given to a task
- 先给需求最少的进程分配时间
- 切换过于频繁：
	- 允许进程暂时超过它的份额

### Combine with MFQ
- ![[操作系统OS/attachments/Pasted image 20220323090606.png]]

## 实时系统调度算法
- 花费时间太长还不如不要调度
- 分类
	- 硬实时
		- 有 ddl
	- 软实时
		- 没有固定的 ddl 但是必须在其他任务之前完成
	- 周期性、非周期性
		- 非周期性就调度不了了
		- 周期性指经过固定时间会请求 CPU 资源，并在下一个周期来之间必须完成
		- process t, deadline d, peroid p
		- m 个进程，周期分别为 $p_i$（指下一个来的时候上一个必须做完），需要 $c_i$ 的处理时间，则必须有
		- $$
	\sum_{i=1}^m\frac{c_i}{p_i}\le 1
	$$
		- 准入控制：CPU 利用率过高已经没有空余资源跑下一个进程就不准入
- 必须支持抢占式、优先级调度

### 单调速率 Rate Monotonic Scheduling
- 单调速率调度
- 优先级是周期的倒数，然后按优先级从高到低执行
	- 有新进程进来也按照这个先计算优先级再按序执行
- Claim：只要是可调度的，单调速率一定能调度；只要单调速率不能调度，这个问题就不能被调度。（证明是一篇论文[ Scheduling Algorithms for Multiprogramming in a Hard-Real-Time Environment](https://dl.acm.org/doi/abs/10.1145/321738.321743)，doi: 10.1145/321738.321743，显然不要求掌握）
- Problem：当周期不成整数倍的时候，理论上 CPU 利用率没到 100 也有单调速率不能调度的情况
	- 事实上，对于单调速率调度，有 N 个实时任务的时候最坏情况 CPU 利用率最高为 $N(2^{\frac{1}{N}}-1)$ ，即！！！（判断能否调度的依据）$\sum\limits_{i=1}^m\frac{c_i}{p_i}\le N(2^{\frac{1}{N}}-1)$

### Earliest deadline First Scheduling (EDF)
- ddl 越早，优先级越高

### Event Latency

### Policy and Mechanisim Separation
- Machanism 怎么做
- Policy 要做什么

## Multiple Process Scheduling
- （比较简略
- 非对称调度
	- 一个主 CPU 负责调度线程
	- 这会导致任务分配不均衡
- 对称调度：每个 CPU 负责调度自己的进程
	- 队列的分配：每个 CPU 一个还是共享一个？
	- 共享一个会有竞争的情况
	- 所以大部分是每个 CPU 各自一个
- 负载均衡
	- 可以 Push 也可以 Pull
- 处理器亲和性

## Linux 调度发展史
### ？
### Completely Fair Scheduler (CFS)
- nice: 越 nice，数字越大，优先级越低

### Windows 优先级调度

## 如何评估调度算法
- Deterministic Evaluation
	- minimum average waiting time
	- 然而事实上单独一个 workload 并不能说明问题，得看它的分布
- 从概率的角度刻画
	- M/M/1 队列（Markov（？
		- 到达时间是泊松分布
		- 服务时间是指数分布
		- 单服务器
		- 队列长度无限
		- FCFS
	- Little's law
	- 平均进程数 $n=\frac{\rho}{1-\rho}$
