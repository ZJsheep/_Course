- 没有内存抽象时的内存管理
	- 三种方式
	- ![[操作系统OS/attachments/Pasted image 20220330082233.png]]
	- 多道程序： ^d69c1e
		- 互相能访问程序
		- 可会能 jmp 到不正确的位置
- 内存抽象要考虑的问题
	- Relocation：就是如何进行内存映射
	- Protection：

# 地址空间

- logical addr, physical addr
- 静态重定位：就是加上一个固定的基址

### Base and Limit Registers

- 动态重定位
- 检查地址是否在 base 和 base+limit 之间
- 或者：先检查逻辑地址是否 < limit register，如果满足，就再加上重定位寄存器（base）得到物理地址
- 现代计算机中，这一堆东西由 MMU 管理
- 看不同粒度的内存管理

## Process level
- 最粗的粒度
- Multiple Partition Allocation
- Fixed Partition
	- 先划分成好多快，来一个进程就给他一块
		- 万一有些要的比 Partition 大，有些要的比 Partition 小
- Variable Partition
	- 根据需要动态分配
	- 问题：会有“空洞”
	- 如果内存用完了，则将这个进程丢到一个足够大的洞里
	- 如果没有足够大的洞，那就丢 swap 里，或者直接 kill 掉
	- 操作系统需要维护：已经被分配的分区、空闲的分区（空洞）
	- Bitmap
		- 内存被分成很多小单元，每一个小单元分配一个 bit，1 表示满，0 表示空
			- Fixed size Bitmap
	- 维护一个链表，维护分区：
		- 1是否被占用/占用的进程
		- 2开始地址
		- 3长度
		- 双向链表更快
		- 分配哪个块：
			- First Fit：第一个放得下的
			- Next Fit：下一个放得下的
				- 是为了少搜一点
				- 实际性能略低于 First Fit
			- Best Fit：放得下中最小的
				- 得搜整个链表
				- 实际上很差，因为会造成很多小洞
			- Worst Fit：找一个最大的
				- 也不太好
			- Quick Fit：额外维护每个大小的块有多少，在哪
	- 碎片
		- 外部碎片
		- 内部碎片
		- First fit 一般会有 0.5N 的块会因为外部碎片被浪费
		- 压缩：过一段时间移动空间并且将碎片拼起来

### Swapping
- 大量时间用在传输数据上
- 如果有 IO，context switch 会用很多时间
- 所以现代操作系统一般不用传统的 swap 而是用一些修改后的版本

## User Level
- 为什么每个应用的内存必须要连续呢：
### Segmentation
- 将某一种类型的数据（代码、数据、符号表）分开存储成一个个段
- 每一个程序都会使用很多个段
- 逻辑地址变成二元组 <段号，offset>
- 每个进程有一个段表，其中每个 entry 包括 Segment Base，Segment Limit
	- 还得存有效位、读写权限信息
	- code sharing at segment level
- STBR：段基址寄存器，指向段表的地址
	- STLR：段长度寄存器，一共有几个段（段号 $s<$ STLR则是合法的
- 好处：
	- （？？？

### Paging
> 目前我们不考虑和 Segmentation 的关系，单考虑分页
- Page Frame：帧 / 页框
- OS 维护一个空闲帧的列表，进程来了以后就去拿几个帧
- 逻辑地址也是二元组 <页号，偏移>
	- 页号 p 是页表的索引，能够索引到页的物理起始地址
	- 偏移 d 就是页内偏移
#### 页表和地址转换✔
- MMU 就是页表和管理地址转换的部件
- 页表
	- 页表在主存中（TLB 在单独的 cache 中
	- seems like （这个表的表项有有 MAX_虚拟页号 那么多）![](attachments/Pasted%20image%2020220430214119.png)结构类似于![](attachments/Pasted%20image%2020220430214139.png)
	- 所以一般虚拟页号比页框号多（不然就没意义了
- 地址转换 ^5f2b76
	- \[ 虚拟页号 | 页内偏移 \]
	- 页框号 = 页表\[虚拟页号\]（\[\] 表示下标索引
	- 页框号 $\times 2^n$ + 页内偏移（就是把页框号粘贴到之前虚拟页号的位置
- 并不是所有的内存中的页都被使用：加入 valid bit，如果无效则说明引用错误
- 好处：
	- Shared Pages
		- 一些复用的代码、数据只要一份
		- fork 更快
		- 动态链接
- Implementation
	- PTBR：Page table base register
	- PTLR：Page table length register
#### 加速 Caches
- TLB 转换检测缓冲区
	- TLB 在单独的 cache 中，比主存（页表所在地）快
	- 会**并行**检查当前需求的虚拟页号是否在 TLB 里
- Translation Lookaside Table 
	- Soft Miss：表项在内存里但不在 TLB 里
	- Hard Miss：表项也不在内存里，得去访问磁盘
	- 硬件控制：
	- 软件控制：提个 Exception，灵活性更高，但是效率较低
	- Consistency：切换 Context 的时候 TLB 就失效了（？
		- 在 TLB Entry 上加上一个 ASID tag（Address Space Identifier）
	- Effctive Access Time（EAT）
		- EAT = $(\epsilon+t)\alpha+(\epsilon+2t)(1-\alpha)$
		- 第一项是 hit，第二项是不 hit，不 hit 要访问两次内存
		- $\alpha$: hit ratio, $\epsilon$: visit TLB, $t$: visit memory
- Virtually Addressed Caches
	- ![[操作系统OS/attachments/Pasted image 20220401120211.png]]
#### 针对大内存的页表
- 多级页表 Multi level page table
- Hash page table
- Inverted Page Table
	- 给物理内存保存他被哪个进程的哪个页用了
	- \<process-id, page-number, offset\>
	- 由 pid 和 p 反向查找是第几个页
	- ![[操作系统OS/attachments/Pasted image 20220408103931.png]]
	- 用 hash 表和 TLB 来加快搜索

#### 页面大小的选择 Page Size
- 如果太大，会浪费内部空间
- 如果太小，TLB 会很大
- ![[操作系统OS/attachments/Pasted image 20220408104843.png]]
### 把两个合起来
- ![[操作系统OS/attachments/Pasted image 20220408105341.png]]
- 用段来管理较大的逻辑单元，包含多个页
- 每个段有它自己的页表
- 物理内存中只需要保存段里面用得到的页就行了，每个段不一定要连续的空间
- 找的时候：先找段描述符，根据 base 和 limit 决定是段里面的哪个页，再在段的页表里找对应的页

## e.g. IA-32 & Linux
- IA-32
- Linux 不支持分段（为了硬件兼容性，RISC V 不支持分段
	- 段基址全是 0，Limit 全是 4 GiB
- Linux Paging：4 级分页，64 位
	- |-Page global-|-Page upper-|-Page middle dir-|-Page table-|-Page-|
	- 在 32 位机上 upper 和 middle 不用

# 虚拟内存
- 只有部分 page 需要丢在内存中程序就能跑
- 这样的话实际需要的空间可以比用的更少，可以突破物理内存的限制，IO 也没那么频繁

### Demand Paging
- 只有当需要用的时候才把页调进内存，内存只保留频繁使用的页
- 在页表上增加一个有效位，如果发现不有效，就提出 Page Fault 调出 OS 来加载这个页
- Lazy Pager：直到页被使用才调进内存
	- Pure Demand Paging：OS 运行的时候内存里啥都没有，第一条指令就提出 Page Fault
	- 问题：一条指令用到了好几个页，都不在内存中
		- 引用的局部性：这样的问题应该不会很频繁地出现
- Pre Paging：预加载页

### Page Fault
- minor page fault：在内存里，只是没更新页表
- major page fault：不在内存里，得去磁盘读
- segmentation fault：非法地址
- OS 处理过程：
- ![attachments/Pasted image 20220408114921.png](attachments/Pasted%20image%2020220408114921.png)![attachments/Pasted image 20220408115308.png](attachments/Pasted%20image%2020220408115308.png) ^de2f79
- 从内存丢掉一个 page 的时候
	- ![[操作系统OS/attachments/Pasted image 20220408115720.png]]
- 总的来说就是三件事：进程发起中断、读取页、重启进程
- Page Fault Rate（p）
- EAT（Effective Access Time）=$(1-p) \times \text{memory access time}+p\times \text{page fault overhead}$ ^d31636
## 调页算法
- ![](attachments/Pasted%20image%2020220501095622.png)
### Optimal
- 调出未来最长时间不用的页
- 这是理想状况，并不能实际实现（因为我们不能预知未来），作为一个 benchmark 和其他方法比较

### FIFO
- 因为先来的页已经放了好久，可能不会用了

### LRU (Least Recently Used)
- 两种实现方式
	- 计数器实现：存被引用时的时钟，替换掉计数器的值最小的
	- 栈实现：用双向链表实现一个栈，里面存页号，每当一个页被用过了就丢栈顶（然后应该是替换掉栈底？ppt 没说
		- 在链表中找到一个页面,删除它,然后把它移动到表头是 一个非常费时的操作（书上写的
- 由于 too costly，通常其他方法都是在近似 LRU，例如 second chance

### Second Chance
- if R = 0: 换掉
	- else if R = 1：不换，令 R = 0
	- R 就是 reference bit！
	- 替换掉在最近时钟间隔内未被引用的旧页面
- 循环队列实现：避免每次都遍历整个列表
	- 指针指向最老的页（？或许只是初始化的时候
	- 一直往前走直到碰到为 0 的页

### NRU (Not Recently Used)
- 青春版 [LRU](3.MemoryManage.md#LRU%20Least%20Recently%20Used)（上面）
- 用两位来保存信息：Reference bit 有没有用过, Modify bit 有没有改过
	- Class 0 (0, 0)：逊耶，换了
	- Class 1 (0, 1)：不太想换，因为换的时候必须写回
	- Class 2 (1, 0)：可能未来会用，不太想换
	- Class 3 (1, 1)：最不想换，因为换了还得写回
	- 从上到下，有这类 class 的页就换掉

- 基于计数的算法：
### NFU (Not Frequently Used)
### Aging Algorithm
- 用移位寄存器
- 每个页有一串 01 串，如果用了就置 1，没用就是 0，然后右移一位
- 每次换出这个值对应的整数最小的

### * Thrashing
- 一个进程拥有的物理页太少了，换的很频繁
- 需要降低多道程序的数量
- 随着多道程序的增加，CPU 利用率先上升后下降，下降就是因为 Thrashing，大量时间花在了调页

### * 引用的局部性
- 时间局部性、空间局部性

### Working Set
- 一个进程在最近 k 次访问中访问最频繁的页，一般不换
	- 近似：当前进程在 $\tau$ 时间内访问的所有页面的集合
- 要换先换不在工作集里的页
- 慢慢 build 这个 working set
- Algorithm
	- 如果 R = 1，更新当前的时间
	- 如果 R = 0 && age > $\tau$：这个页滚出 working set
	- 如果 R = 0 && age $\le\tau$：保留

### WSClock
- ![[操作系统OS/attachments/Pasted image 20220413092447.png]]![[操作系统OS/attachments/Pasted image 20220413092458.png]]
### Page Buffering
![[操作系统OS/attachments/Pasted image 20220413093219.png]]

### Backing Store
- 页被换出去之后存在磁盘的一个单独分区中，直接向磁盘发起 IO，而不是通过文件系统的 IO，这样更快

## Local & Global Policies
![[操作系统OS/attachments/Pasted image 20220413093804.png]]

### Global
- 得由 OS 考虑
- 每个进程至少需要多少页
- 还得考虑调度（？
- Page Fault Frequency

## Kernal 的页调度
- Linux：Buddy System
- 向 2 的整数次幂上取整
- 建立一个很多个链表，第 k 个链表都是一系列大小为 2^k 的块
- Slab Allocator
	- Buddy System：内部浪费很大，会导致很多 Slab
	- Page Replacement：
		- PFRA (Page Frame Reclaiming Algorithm): 对页分类：
			- Unreclaimable
			- ???

### OS Support for Paging
- 没讲，自己看

